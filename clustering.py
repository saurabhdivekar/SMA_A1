# -*- coding: utf-8 -*-
"""Clustering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PkWAcnF8f_V_NF-1j516cQnjjjtKE646

**Mounting Drive**
"""

from google.colab import drive
drive.mount('/content/drive')

!cd "/content/drive/MyDrive/A1/"

"""**Import Library**"""

from sklearn.cluster import SpectralClustering
import matplotlib.pyplot as plt
from numpy import random
import time
import networkx as nx
import networkx.algorithms.community as nx_comm

g1 = nx.read_gml('/content/drive/MyDrive/A1/karate.gml', label = 'id')
g2 = nx.read_gml('/content/drive/MyDrive/A1/dolphins.gml')
g3 = nx.read_weighted_edgelist('/content/drive/MyDrive/A1/jazz.net')

"""**Graph1**"""

adj_matrix = nx.to_numpy_matrix(g1)

seconds_old = time.time()

sc = SpectralClustering(n_clusters=4, affinity='precomputed', n_init=100)

"""**Find Communities in the Graph**"""

sc.fit(adj_matrix)

"""**Time Taken**"""

seconds_new = time.time()
print("Time taken : ", seconds_new - seconds_old)

"""**find the nodes forming the communities**"""

labels = sc.labels_
ls = [[] for i in range(4)]
i = 1
for x in labels:
    if(x == 0):
        ls[0].append(i)
        i += 1
    elif(x == 1):
        ls[1].append(i)
        i += 1
    elif(x == 2):
        ls[2].append(i)
        i += 1
    elif(x == 3):
        ls[3].append(i)
        i += 1

"""**Results**"""

print("Clusters : ")
print(ls)
print("Number of Clusters : ")
print(len(ls)) 
print("Modularity : " + str(nx_comm.modularity(g1, ls)))
print("=====================================================================================")

"""**Graph 2**"""

adj_matrix = nx.to_numpy_matrix(g2)

"""**Converting Graph to List**"""

lsg2 = list(g2)
seconds_old = time.time()

sc = SpectralClustering(n_clusters=4, affinity='precomputed', n_init=100)

"""**find communities in the graph**"""

sc.fit(adj_matrix)

seconds_new = time.time()
print("Time taken : ", seconds_new - seconds_old)

"""**find the nodes forming the communities**"""

labels = sc.labels_

ls = [[] for i in range(4)]

i = 0
for x in labels:
    if(x == 0):
        ls[0].append(lsg2[i])
        i += 1
    elif(x == 1):
        ls[1].append(lsg2[i])
        i += 1
    elif(x == 2):
        ls[2].append(lsg2[i])
        i += 1
    elif(x == 3):
        ls[3].append(lsg2[i])
        i += 1

"""**Results**"""

print("Clusters : ")
print(ls)
print("Number of Clusters : ")
print(len(ls)) 
print("Modularity : " + str(nx_comm.modularity(g2, ls)))
print("=====================================================================================")

"""**Graph 3**"""

adj_matrix = nx.to_numpy_matrix(g3)

seconds_old = time.time()

sc = SpectralClustering(n_clusters=4, affinity='precomputed', n_init=100)

"""**find communities in the graph**"""

sc.fit(adj_matrix)

seconds_new = time.time()
print("Time taken : ", seconds_new - seconds_old)

"""**find the nodes forming the communities**"""

labels = sc.labels_

ls = [[] for i in range(4)]

i = 1
for x in labels:
    if(x == 0):
        ls[0].append(str(i))
        i += 1
    elif(x == 1):
        ls[1].append(str(i))
        i += 1
    elif(x == 2):
        ls[2].append(str(i))
        i += 1
    elif(x == 3):
        ls[3].append(str(i))
        i += 1

"""**Results**"""

print("Clusters : ")
print(ls)
print("Number of Clusters : ")
print(len(ls)) 
#print("Modularity : " + str(nx_comm.modularity(g3, ls)))
print("=====================================================================================")

import itertools
import networkx as nx
from networkx.algorithms.community.centrality import girvan_newman
from networkx.algorithms.community import greedy_modularity_communities
import networkx.algorithms.community as nx_comm
import numpy as np
from sklearn.cluster import SpectralClustering


Graph1=nx.read_gml('/content/drive/MyDrive/A1/karate.gml', label = 'id')
k = 15
comp = girvan_newman(Graph1)
for communities in itertools.islice(comp, k):
    print(tuple(sorted(c) for c in communities))
#print(nx_comm.modularity(Graph1, nx_comm.label_propagation_communities(Graph1)))        
print(len(communities))   #no_of_clusters



Graph3 = nx.read_gml('/content/drive/MyDrive/A1/dolphins.gml')
k = 15
comp = girvan_newman(Graph3)
for communities in itertools.islice(comp, k):
    print(tuple(sorted(c) for c in communities))
print(len(communities))   #no_of_clusters


Graph2 = nx.read_weighted_edgelist('/content/drive/MyDrive/A1/jazz.net')


c = list(greedy_modularity_communities(Graph1))

print("*******************************************************************************")
for x in c:
    print(sorted(x))
print(len(c) )  #no_of_clusters 

c = list(greedy_modularity_communities(Graph2))

print("*******************************************************************************")
for x in c:
    print(sorted(x))
print(len(c) )  #no_of_clusters


c = list(greedy_modularity_communities(Graph3))

print("*******************************************************************************")
for x in c:
    print(sorted(x))
print(len(c) )  #no_of_clusters





print("*******************************************************************************")

adj_mat = nx.to_numpy_matrix(Graph1)

sc = SpectralClustering(4, affinity='precomputed', n_init=100)
sc.fit(adj_mat)

print('spectral clustering')
print(sc.labels_)



adj_mat = nx.to_numpy_matrix(Graph2)

sc = SpectralClustering(4, affinity='precomputed', n_init=100)
sc.fit(adj_mat)

print('spectral clustering')
print(sc.labels_)



adj_mat = nx.to_numpy_matrix(Graph3)

sc = SpectralClustering(4, affinity='precomputed', n_init=100)
sc.fit(adj_mat)

print('spectral clustering')
print(sc.labels_)

import networkx as nx
dg = nx.read_gml('/content/drive/MyDrive/A1/dolphins.gml')
print("Dolphins Statistics")
print(nx.info(dg))
print("Avg path length : ", nx.average_shortest_path_length(dg))
average = nx.average_clustering(dg)
print("Avg clustering coefficient : ", average)
print("-----------------------------------------")



print("Karate Club Statistics")
kg = nx.read_gml('/content/drive/MyDrive/A1/karate.gml', label = 'id')
print(nx.info(kg))
print("Avg path length : ", nx.average_shortest_path_length(kg))
average = nx.average_clustering(kg)
print("Avg clustering coefficient : ", average)
print("-----------------------------------------")


print("Jazz Statistics")
f = open("/content/drive/MyDrive/A1/jazz.net","r")
lines = f.readlines()
f.close()
nf = open("jazz.net","w")
for i in lines:
    if i != lines[0] and i != lines[1] and i != lines[2]:
        nf.write(i)
nf.close()
jg = nx.read_weighted_edgelist("jazz.net")
print(nx.info(jg))
print("Avg path length : ", nx.average_shortest_path_length(jg))
average = nx.average_clustering(jg)
print("Avg clustering coefficient : ", average)
print("*****End****")