# -*- coding: utf-8 -*-
"""GVN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a4vKt4fWMKRKW_jboJYKb6jKxOo-Ud2d

***Importing Dataset***
"""

from google.colab import drive
drive.mount('/content/drive')

"""**Importing Libraries**"""

import matplotlib.pyplot as plt
import networkx.algorithms.community as nx_comm
import time

import numpy as np
import networkx as nx
from tabulate import tabulate

!cd "/content/drive/MyDrive/A1/"

"""**Finding count of connected component**"""

def girvan_newman(graph):
 
    sgraph = nx.connected_components(graph)
    sg_c = nx.number_connected_components(graph)

    while(sg_c == 1):
        graph.remove_edge(edge_to_remove(graph)[0], edge_to_remove(graph)[1])
        sgraph = nx.connected_components(graph)
        sg_c = nx.number_connected_components(graph)

    return sgraph

"""**Read Database**"""

g1 = nx.read_gml('/content/drive/MyDrive/A1/karate.gml', label = 'id')
g2 = nx.read_gml('/content/drive/MyDrive/A1/dolphins.gml')
g3 = nx.read_weighted_edgelist('/content/drive/MyDrive/A1/jazz.net')

"""**Graph 1**"""

seconds_old = time.time()

"""**Communities in the Graph**"""

communities1 = girvan_newman(g1.copy())

"""**Find the Nodes Forming the Communities**"""

node_groups1 = []

for i in communities1:
    node_groups1.append(list(i))

seconds_new = time.time()
print("Time Required : ", seconds_new - seconds_old)

"""**Result**"""

print("Clusters : ")
print(node_groups1)
print("******************************************")   
print("Count of Clusters : ")
print(len(node_groups1))   
print("******************************************")
print("Modularity G1: " + str(nx_comm.modularity(g1, node_groups1)))
print("******************************************")

"""**Graph 2**"""

seconds_old = time.time()

"""**Find Communities in Graph**"""

c2 = girvan_newman(g2.copy())

"""**find the nodes forming the communities**"""

node_groups2 = []

for i in c2:
    node_groups2.append(list(i))
seconds_new = time.time()

"""**Results**"""

print("Time taken : ", seconds_new - seconds_old)
print("Clusters : ")
print(node_groups2)    
print("******************************************")
print("Number of Clusters : ")
print(len(node_groups2))  
print("******************************************")
print("Modularity : " + str(nx_comm.modularity(g2, node_groups2)))
print("******************************************")

"""**Graph 3**"""

seconds_old = time.time()

"""**Find Communities in Graph**"""

cluster3 = girvan_newman(g3.copy())

"""**Find the Nodes Forming the Communities**"""

node_groups3 = []
for i in cluster3:
    node_groups3.append(list(i))

seconds_new = time.time()

"""**Results**"""

print("Time taken : ", seconds_new - seconds_old)
print("******************************************")
print("Clusters : ")
print(node_groups3)  
print("******************************************")
print("Number of Clusters : ")
print(len(node_groups3))  
print("******************************************")
print("Modularity : " + str(nx_comm.modularity(g3, node_groups3)))
print("******************************************")

import itertools
import networkx as nx
from networkx.algorithms.community.centrality import girvan_newman
from networkx.algorithms.community import greedy_modularity_communities
import networkx.algorithms.community as nx_comm
import numpy as np
from sklearn.cluster import SpectralClustering


Graph1=nx.read_gml('/content/drive/MyDrive/A1/karate.gml', label = 'id')
k = 15
comp = girvan_newman(Graph1)
for communities in itertools.islice(comp, k):
    print(tuple(sorted(c) for c in communities))
#print(nx_comm.modularity(Graph1, nx_comm.label_propagation_communities(Graph1)))        
print(len(communities))   #no_of_clusters



Graph3 = nx.read_gml('/content/drive/MyDrive/A1/dolphins.gml')
k = 15
comp = girvan_newman(Graph3)
for communities in itertools.islice(comp, k):
    print(tuple(sorted(c) for c in communities))
print(len(communities))   #no_of_clusters


Graph2 = nx.read_weighted_edgelist('/content/drive/MyDrive/A1/jazz.net')


c = list(greedy_modularity_communities(Graph1))

print("*******************************************************************************")
for x in c:
    print(sorted(x))
print(len(c) )  #no_of_clusters 

c = list(greedy_modularity_communities(Graph2))

print("*******************************************************************************")
for x in c:
    print(sorted(x))
print(len(c) )  #no_of_clusters


c = list(greedy_modularity_communities(Graph3))

print("*******************************************************************************")
for x in c:
    print(sorted(x))
print(len(c) )  #no_of_clusters





print("*******************************************************************************")

adj_mat = nx.to_numpy_matrix(Graph1)

sc = SpectralClustering(4, affinity='precomputed', n_init=100)
sc.fit(adj_mat)

print('spectral clustering')
print(sc.labels_)



adj_mat = nx.to_numpy_matrix(Graph2)

sc = SpectralClustering(4, affinity='precomputed', n_init=100)
sc.fit(adj_mat)

print('spectral clustering')
print(sc.labels_)



adj_mat = nx.to_numpy_matrix(Graph3)

sc = SpectralClustering(4, affinity='precomputed', n_init=100)
sc.fit(adj_mat)

print('spectral clustering')
print(sc.labels_)

import networkx as nx
dg = nx.read_gml('/content/drive/MyDrive/A1/dolphins.gml')
print("Dolphins Statistics")
print(nx.info(dg))
print("Avg path length : ", nx.average_shortest_path_length(dg))
average = nx.average_clustering(dg)
print("Avg clustering coefficient : ", average)
print("-----------------------------------------")



print("Karate Club Statistics")
kg = nx.read_gml('/content/drive/MyDrive/A1/karate.gml', label = 'id')
print(nx.info(kg))
print("Avg path length : ", nx.average_shortest_path_length(kg))
average = nx.average_clustering(kg)
print("Avg clustering coefficient : ", average)
print("-----------------------------------------")


print("Jazz Statistics")
f = open("/content/drive/MyDrive/A1/jazz.net","r")
lines = f.readlines()
f.close()
nf = open("jazz.net","w")
for i in lines:
    if i != lines[0] and i != lines[1] and i != lines[2]:
        nf.write(i)
nf.close()
jg = nx.read_weighted_edgelist("jazz.net")
print(nx.info(jg))
print("Avg path length : ", nx.average_shortest_path_length(jg))
average = nx.average_clustering(jg)
print("Avg clustering coefficient : ", average)
print("*****End****")