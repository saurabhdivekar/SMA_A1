# -*- coding: utf-8 -*-
"""modularity.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UoDZxzanHjvye81wOtlP2HihQhIy25bF
"""

from google.colab import drive
drive.mount('/content/gdrive')

from networkx.algorithms.community.modularity_max import greedy_modularity_communities
import time
import networkx as nx
import networkx.algorithms.community as nx_comm

!cd "/content/gdrive/MyDrive/A1/"

graph1 = nx.read_gml('/content/gdrive/MyDrive/A1/karate.gml', label = 'id')
graph2 = nx.read_gml('/content/gdrive/MyDrive/A1/dolphins.gml')
graph3 = nx.read_weighted_edgelist('/content/gdrive/MyDrive/A1/jazz.net')

# Graph1
seconds_old = time.time()

# finding the communities in the graph
community1 = greedy_modularity_communities(graph1)

seconds_new = time.time()
print("Time taken : ", seconds_new - seconds_old)

#  to find the nodes which are forming the communities
node_groups1 = (list(sorted(c) for c in community1))

print("Clusters : ")
print(node_groups1)   
print("Number of Clusters : ")
print(len(node_groups1))  
print("Modularity : " + str(nx_comm.modularity(graph1, node_groups1)))

# Graph2
seconds_old = time.time()

# finding the communities in the graph
community2 = greedy_modularity_communities(graph2)

seconds_new = time.time()
print("Time taken : ", seconds_new - seconds_old)

# to find the nodes which are forming the communities
node_groups2 = (list(sorted(c) for c in community2))

print("Clusters : ")
print(node_groups2)   
print("Number of Clusters : ")
print(len(node_groups2))  
print("Modularity : " + str(nx_comm.modularity(graph2, node_groups2)))

# Graph3
seconds_old = time.time()

# finding the communities in the graph
community3 = greedy_modularity_communities(graph3)

seconds_new = time.time()
print("Time taken : ", seconds_new - seconds_old)

# to find the nodes which are forming the communities
node_groups3 = (list(sorted(c) for c in community3))

print("Clusters : ")
print(node_groups3)   
print("Number of Clusters : ")
print(len(node_groups3))  
print("Modularity : " + str(nx_comm.modularity(graph3, node_groups3)))

import itertools
import networkx as nx
from networkx.algorithms.community.centrality import girvan_newman
from networkx.algorithms.community import greedy_modularity_communities
import networkx.algorithms.community as nx_comm
import numpy as np
from sklearn.cluster import SpectralClustering


Graph1=nx.read_gml('/content/drive/MyDrive/A1/karate.gml', label = 'id')
k = 15
comp = girvan_newman(Graph1)
for communities in itertools.islice(comp, k):
    print(tuple(sorted(c) for c in communities))
#print(nx_comm.modularity(Graph1, nx_comm.label_propagation_communities(Graph1)))        
print(len(communities))   #no_of_clusters



Graph3 = nx.read_gml('/content/drive/MyDrive/A1/dolphins.gml')
k = 15
comp = girvan_newman(Graph3)
for communities in itertools.islice(comp, k):
    print(tuple(sorted(c) for c in communities))
print(len(communities))   #no_of_clusters


Graph2 = nx.read_weighted_edgelist('/content/drive/MyDrive/A1/jazz.net')


c = list(greedy_modularity_communities(Graph1))

print("_____________________________________________")
for x in c:
    print(sorted(x))
print(len(c) )  #no_of_clusters 

c = list(greedy_modularity_communities(Graph2))

print("_____________________________________________")
for x in c:
    print(sorted(x))
print(len(c) )  #no_of_clusters


c = list(greedy_modularity_communities(Graph3))

print("_____________________________________________")
for x in c:
    print(sorted(x))
print(len(c) )  #no_of_clusters





print("___________________________________")

adj_mat = nx.to_numpy_matrix(Graph1)

sc = SpectralClustering(4, affinity='precomputed', n_init=100)
sc.fit(adj_mat)

print('spectral clustering')
print(sc.labels_)



adj_mat = nx.to_numpy_matrix(Graph2)

sc = SpectralClustering(4, affinity='precomputed', n_init=100)
sc.fit(adj_mat)

print('spectral clustering')
print(sc.labels_)



adj_mat = nx.to_numpy_matrix(Graph3)

sc = SpectralClustering(4, affinity='precomputed', n_init=100)
sc.fit(adj_mat)

print('spectral clustering')
print(sc.labels_)

import networkx as nx
dg = nx.read_gml('/content/drive/MyDrive/A1/dolphins.gml')
print("Dolphins Statistics ")
print(nx.info(dg))
print("Avg path length : ", nx.average_shortest_path_length(dg))
average = nx.average_clustering(dg)
print("Avg clustering coefficient : ", average)




print("Karate Club Statistics ")
kg = nx.read_gml('/content/drive/MyDrive/A1/karate.gml', label = 'id')
print(nx.info(kg))
print("Avg path length : ", nx.average_shortest_path_length(kg))
average = nx.average_clustering(kg)
print("Avg clustering coefficient : ", average)



print("Jazz Statistics ")
f = open("/content/drive/MyDrive/A1/jazz.net","r")
lines = f.readlines()
f.close()
nf = open("jazz.net","w")
for i in lines:
    if i != lines[0] and i != lines[1] and i != lines[2]:
        nf.write(i)
nf.close()
jg = nx.read_weighted_edgelist("jazz.net")
print(nx.info(jg))
print("Avg path length : ", nx.average_shortest_path_length(jg))
average = nx.average_clustering(jg)
print("Avg clustering coefficient : ", average)